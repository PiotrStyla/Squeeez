# Hutter Lab - Compression Research

Projekt badawczy nad kompresjÄ… dla **Hutter Prize** (500,000â‚¬ za najlepszÄ… kompresjÄ™ enwik9).

## ğŸ¯ Cel

ZbudowaÄ‡ kompresor, ktÃ³ry:
- OsiÄ…ga lepszÄ… kompresjÄ™ niÅ¼ obecne rekordy na enwik9 (1 GB Wikipedii)
- UÅ¼ywa **out-of-the-box** podejÅ›cia: wielokanaÅ‚owe modelowanie struktury Wiki
- SpeÅ‚nia wymagania Hutter Prize (samodzielne exe, bez zewnÄ™trznych danych, < 70k/T godzin)

## ğŸ“Š Dotychczasowe wyniki

### Test na sample.txt (2,372 bajty):

| Model | Rozmiar danych | Bity/bajt | Poprawa vs zlib |
|-------|----------------|-----------|-----------------|
| zlib poziom 9 | 1,136 B | 3.831 | baseline |
| Order-0 | 1,315 B | 4.435 | -16% |
| Order-1 | 943 B | 3.180 | +17% |
| Order-2 | 528 B | 1.781 | +53% |
| **Order-3** | **226 B** | **0.762** | **+80%** ğŸ¯ |

## ğŸ›  Komponenty

### 1. `arithmetic_coder.py`
- Implementacja arithmetic coding z precyzjÄ… caÅ‚kowitoliczbowÄ…
- Enkoder i dekoder z normalizacjÄ… zakresÃ³w
- Wsparcie dla dowolnych modeli probabilistycznych

### 2. `context_model.py`
- Model Order-N (n-gram) z backoff mechanism
- Trenowanie na danych (statyczny model)
- Wersja adaptacyjna (model aktualizuje siÄ™ podczas kodowania)
- Serializacja/deserializacja modelu

### 3. `compress_context.py`
- PeÅ‚ny pipeline kompresji z modelem kontekstowym
- Test rÃ³Å¼nych wartoÅ›ci Order (0, 1, 2, 3)
- Weryfikacja poprawnoÅ›ci dekompresji
- PorÃ³wnanie z zlib

## ğŸš€ Jak uÅ¼ywaÄ‡

### Podstawowy test:
```bash
python compress_context.py
```

To uruchomi testy Order-0 do Order-3 na `data/sample.txt`.

### Pobierz prawdziwe dane enwik:
```bash
python download_enwik.py
```

Opcje:
- enwik8 (100 MB) - szybsze testy
- enwik9 (1 GB) - peÅ‚ny konkurs
- Fragment 10 MB - do szybkich eksperymentÃ³w

### Test na wiÄ™kszym pliku:
```python
python compress_context.py  # edytuj input_file w test_multiple_orders()
```

## ğŸ“ˆ Plan rozwoju

### âœ… UkoÅ„czone:
1. Åšrodowisko Python + baseline (zlib)
2. Arithmetic coder od podstaw
3. Model Order-0 (statystyka globalna)
4. Model Order-1 do Order-3 (konteksty n-gram)

### ğŸ”„ W toku:
5. Test na wiÄ™kszym fragmencie enwik9

### ğŸ“ Planowane:
6. **Parser struktury Wikipedia:**
   - Wykrywanie nagÅ‚Ã³wkÃ³w `== Sekcja ==`
   - Wydzielanie linkÃ³w `[[ArtykuÅ‚]]`
   - Parsowanie szablonÃ³w `{{Template|param=value}}`
   - Osobne kanaÅ‚y dla rÃ³Å¼nych typÃ³w treÅ›ci

7. **WielokanaÅ‚owe modelowanie:**
   - Osobne modele Order-N dla kaÅ¼dego kanaÅ‚u
   - Model hierarchiczny (tytuÅ‚ â†’ sekcja â†’ treÅ›Ä‡)
   - Cross-attention miÄ™dzy kanaÅ‚ami

8. **Neural language model:**
   - MaÅ‚y Transformer/RNN dla kaÅ¼dego kanaÅ‚u
   - Kwantyzacja wag (4-bit, 8-bit)
   - Destylacja z wiÄ™kszego modelu

9. **Port do C++:**
   - Przepisanie do C++ (bez zaleÅ¼noÅ›ci)
   - Optymalizacja pod single-core CPU
   - Minimalizacja rozmiaru exe (zip compression)

10. **Hutter Prize submission:**
    - SpeÅ‚nienie wszystkich wymagaÅ„
    - Dokumentacja
    - Submission package

## ğŸ§  Kluczowe insight'y

### Dlaczego Order-3 jest taki dobry?
- Przewiduje znak na podstawie 3 poprzednich znakÃ³w
- W tekÅ›cie naturalnym (Wikipedia) kontekst 3-4 znakÃ³w daje ogromnÄ… informacjÄ™
- PrzykÅ‚ad: po "the" najczÄ™Å›ciej jest spacja, po "qu" prawie zawsze "e"

### Dlaczego model jest duÅ¼y na maÅ‚ym pliku?
- Model Order-3 potrzebuje przechowaÄ‡ statystyki dla ~1400 kontekstÃ³w
- Na maÅ‚ym pliku (2 KB) to dominuje rozmiar
- Na enwik9 (1 GB) model bÄ™dzie ~50 KB = 0.005% caÅ‚oÅ›ci
- W finalnym exe model jest zip-owany, wiÄ™c powtarzalne struktury siÄ™ dobrze pakujÄ…

### Co dalej?
- Dla Wikipedii moÅ¼emy wykorzystaÄ‡ jej **strukturÄ™**:
  - NagÅ‚Ã³wki sÄ… przewidywalne (`== Introduction ==`, `== History ==`)
  - Linki majÄ… regularny format `[[Article|text]]`
  - Szablony `{{cite|...}}` teÅ¼
- Zamiast jednego modelu na wszystko, zbudujemy **ekspertÃ³w** dla rÃ³Å¼nych czÄ™Å›ci
- To jest "out of the box" approach, ktÃ³ry moÅ¼e daÄ‡ przewagÄ™ nad PAQ/cmix

## ğŸ“š Zasoby

- [Hutter Prize oficjalna strona](http://prize.hutter1.net/)
- [Arithmetic coding - Wikipedia](https://en.wikipedia.org/wiki/Arithmetic_coding)
- [PPM compression](https://en.wikipedia.org/wiki/Prediction_by_partial_matching)
- [Current records](http://prize.hutter1.net/hfaq.htm#current)

## ğŸ“ Notatki

### 2024-11-21
- Utworzono projekt
- Zaimplementowano arithmetic coder
- OsiÄ…gniÄ™to 0.762 bity/bajt na Order-3 (80% lepsze niÅ¼ zlib na maÅ‚ym pliku)

### 2024-11-22
- Przetestowano na 10 MB enwik8: **2.36 bity/bajt** (19.9% lepsze niÅ¼ zlib)
- Projekcja na enwik9 (1 GB): ~281 MB vs 351 MB (zlib) = **70 MB oszczÄ™dnoÅ›ci**
- Zbudowano parser struktury Wiki
- Analiza: 74% czysty tekst, 25.6% markup, ~9,300 linkÃ³w/MB
- Strategia wielokanaÅ‚owa potwierdzona jako obiecujÄ…ca

---

**Status:** ğŸŸ¢ Faza 1 ukoÅ„czona - baseline dziaÅ‚a lepiej niÅ¼ zlib
**NastÄ™pny milestone:** Implementacja wielokanaÅ‚owego kompresora (osobne modele dla linkÃ³w/nagÅ‚Ã³wkÃ³w/tekstu)
